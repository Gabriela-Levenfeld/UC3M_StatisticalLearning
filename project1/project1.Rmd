---
title: 'Project 1: Statistical Tools'
author: "Gabriela Levenfeld Sabau"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: '6'
    df_print: paged
  geometry: left=3cm,right=3cm,top=2cm,bottom=2cm
  mathjax: local
  self_contained: false
  word_document:
    toc: true
    toc_depth: '6'
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 6
    keep_tex: true
subtitle: MS in Statistics for Data Science
bibliography: references.bib
biblio-style: ieee
nocite: '@*'
link-citations: true
linkcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

\pagebreak

# Introduction

## Dataset description

The dataset used for develop this task is available on Kaggle [@kaggle_telco_churn] and contains information of a Telco company from $7043$ clients, distributed across $21$ different variables such as `gender`, `MonthlyCharges`, and `PhoneService`, among others.

In business sector, knowing the number of customers gained and lost is crucial for making profit. Thus, analyzing if a client is thinking about changing its services into another company can help to evaluate and make new company's strategies. This dataset is designed in order to predict customer churn, where it has been collect the final decision for each client.


## Variables description

The information contained in the dataset can be group into different areas:

**Personal information**.

-   `customerID`; A unique identifier for the client.

-   `gender`; The customer's gender, Female or Male.

-   `SeniorCitizen`;  Binary variable indicating if the customer is older than 65 (Yes) or not (No).

-   `Partner`; Binary variable which storage whether the customer has a partner (Yes) or not (No).

-   `Dependents`; Binary variable that indicates if the client lives with more people (Yes) or not (No).

**Services subscribed**.

-   `tenure`; The number of moths the customer has been with the company by the end of the third quarter (3Q).

-   `PhoneService`; Whether the customer subscribes to home phone service (Yes or No).

-   `MultipleLines`; Whether the customer has more than one telephone lines (Yes or No). This service is on ly available if the user has active the `PhoneService`.

-   `InternetService`; Type of subscription to Internet service (No, DSL, Fiber Optic, or Cable).

The following extra-services are only available for user who has active the `InternetService` (the company does not charge any additional fee).

-   `OnlineSecurity`; Whether the customer subscribes to an online security service (Yes or No).

-   `OnlineBackup`; Whether the customer subscribes to an online backup service (Yes or No).

-   `DeviceProtection`; Whether the customer subscribes to a device protection plan (Yes or No).

-   `TechSupport`; Whether the customer subscribes to a technical support plan from the company with reduced wait times (Yes or No).

-   `StreamingTV`; Whether the customer use the Internet service to stream television programming (Yes, No).

-   `StreamingMovies`; Whether the customer use the Internet service to stream movies (Yes, No).

**Account information**

-   `Contract`; The type of contract that the customer have signed (Month-to-Month, One Year, Two Year).

-   `PaperlessBilling`; Whether the customer has chosen paperless billing (Yes or No).

-   `PaymentMethod`; Customer payment method (Bank Withdrawal, Credit Card, or Mailed Check)

-   `MonthlyCharges`; Customer monthly charges for all services from the company.

-   `TotalCharges`; Total expenses calculated to the end of the 3Q (third quarter).

**Target variable**

-   `Churn`; Whether the customer left the company (Yes) this quarter or stay with the company (No).

## Goal

The objective of this assignment is to predict the `Churn` variable, which represents whether a client will remain with or leave from the company's services within the coming time period. This prediction task is a binary classification problem where the goal is to forecast one of the two possible outcomes: churn yes (leave the company) or churn no (stay with the company services).

This valuable information can provide insights to the company, that allow it to form better strategies and enhance customer retention by optimizing service offering, as well as increase its profitability.

\pagebreak

# Data preprocessing

In this first section, we must prepare the dataset in order to use it for the computational model. This means handling missing data, deleting unnecessary information, encoding categorical variables and splitting the data, among other.

## 1. Load material.

**Load libraries**. Several libraries are need for the project in order to work properly.

```{r load_libraries, message=FALSE, warning=FALSE}
library(skimr)
library(tidyverse) # For glimpse
library(dplyr) # mutate function
library(mice) # Imputation
library(VIM) # Imputation graph
library(fastDummies) # For encoding multi-state variables
library(caret) # For split the dataset
library(ggplot2) # Plots
library(GGally) # For plots of the continuous variables
library(pander) # For making tables
library(gridExtra) # For grid.arrange
library(reshape2) # For melt function
library(corrplot) # For correlation matrix
library(MASS) # For qda and lda
```

**Load dataset**.

```{r load_data}
# Load the dataset for this project
data <- read.csv("Telco-Customer-Churn.csv", header = TRUE, sep = ",")
```

**First look at the dataset**.

```{r small_EDA1, eval=FALSE, include=FALSE}
# Small Exploratory Data Analysis
#skim(data)
# Presents results for every column; the statistics it provides depend on the class of the variable

# For visualize the first 2 rows
#head(data, 2)
```

```{r small_EDA2}
glimpse(data)
```


## 2. Delete unnecessary information.

Thanks to the above function, we realized we can remove the ID column (`customerID`) because it will not be useful for making predictions. On the other hand, `PaperlessBilling` is also removed, due to nowadays we live in a digital era thus most people choose electronic payments and it will not really provide any additional information to the problem we are dealing with.

```{r rmv_columns}
# Remove ID column 
data <- data %>% dplyr::select(-c(customerID, PaperlessBilling))
```

## 3. Data cleaning.

By analyzing the dataset we can realized that there exists some variables that are quite intertwine.

\underline{Combine `PhoneService` and `MultipleLines`}. The first variable indicates if the client has sign up for home phone service or not. Only when the client has hired for this service, he can choose between having $1$ phone line (`MultipleLines`=No) or have more than $1$ (`MultipleLines`=Yes). This relationship lead us into three possible scenarios:

1.  `PhoneService`=No and `MultipleLines`="No phone service". Customers who do not have phone service.

2.  `PhoneService`=Yes and `MultipleLines`=No. Customers who have phone service and choose to have a single line.

3.  `PhoneService`=Yes and `MultipleLines`=Yes. Customers who have phone service and choose to have multiple lines.

Since `MultipleLines` can be consider to have all the information needed, I will combine this two variables on a new parameter named `PhoneServiceType` and treat it as a multi-state category with three options:

-   $0$: if there is no phone service.

-   $1$: if there is phone service with a single line.

-   $2$: if there is phone service with multiple lines.

\underline{`InternetService` and its associate variables}. Something similar happend on this situation. Clients who have no sign up for Internet service, they are no be able to sign up for extra-services associated with it such as `OnlineSecurity`, `StreamingTV`, among others. The dataset storage this information of extra-services with "Yes", "No" or "No internet service". It is clearly that we can reduce this multi-state variables issue into a binary class. So "No phone service" will be understand simply as the customer does not have this service on (setting the parameter value into "No").

**Note**: For both situation, we check there was no mistake on the data. So it has been computationally verified that there is concordance between the relationships of these variables. Thus avoiding the existence of possible nonsense situations.

```{r data_cleaning, echo=TRUE, results='hide'}
## Unique values of each variable ----------------------------------------------
unique(data$SeniorCitizen) # It is already transform in 1's and 0's
data$SeniorCitizen <- factor(data$SeniorCitizen, 
                             levels = c(0, 1), 
                             labels = c("No", "Yes"))
unique(data$SeniorCitizen)


cat_vars <- sapply(data, is.character) # Select qualitative variables
lapply(data[, cat_vars], unique) # Print unique values


## PhoneService and MultipleLines ----------------------------------------------
# Subset with clients where PhoneService is "No"
subset_no_Phone <- data[data$PhoneService == "No", ]
# Check MultipleLines is set to "No phone service"
if (all(subset_no_Phone$MultipleLines == "No phone service")) {
  cat("In the subset where PhoneService is 'No', 
      MultipleLines is set to 'No phone service' only.\n")
} else {
  cat("In the subset where PhoneService is 'No', 
      MultipleLines is not exclusively set to 'No phone service'.\n")
}

# Combine PhoneService and MultipleLines on a new variable (PhoneServiceType)
# Convert into a factor
data <- data %>%
  mutate(PhoneServiceType = case_when(
    MultipleLines == "No phone service" ~ "NoPhone",
    MultipleLines == "No" ~ "PhoneSingle",
    MultipleLines == "Yes" ~ "PhoneMultiple"
  )) %>%
  mutate(PhoneServiceType = factor(PhoneServiceType, levels = c("NoPhone", "PhoneSingle", "PhoneMultiple")))

# Remove original variables
data <- dplyr::select(data, -PhoneService, -MultipleLines)


## Consequences Internet service -----------------------------------------------
# Subset with clients where InternetService is "No"
subset_no_Internet <- data[data$InternetService == "No", ]

vars_to_check <- c("OnlineSecurity", "OnlineBackup", "DeviceProtection",
                   "TechSupport", "StreamingTV", "StreamingMovies")

# Check its associate variables are set to "No internet service"
for (variable in vars_to_check) {
  unique_values <- unique(subset_no_Internet[[variable]])
  cat("Unique values for", variable, ":", unique_values)
  cat("\n")
}

# Reduce the associate variables to a binary class ("No internet service" -> "No")
for (variable in vars_to_check) {
  data[[variable]] <- ifelse(data[[variable]] == "No internet service", "No", data[[variable]])
}
```

## 4. Handling missing data.

On this dataset there are some missing values contained in the variable `TotalCharges` which we need to handle it first in order to be able to use the statistical tools after.

Take in mind, these values represent only $0.1561834\%$ of customers in the dataset, the following approach could be followed:

-   **Delete this rows**; due to the low presence of missing values the data will not be affected.

-   **Set to** $0$; these observations correspond to new clients, therefore, note it has not passed enough time to compute this value.

-   **Imputation**; selected option thereby some techniques seen during lecture can be apply.

For imputing the missing data the R library call `mice` is used. Instead of making a random prediction, `mice` by default makes $5$. However, in this exercise we will only choose the first of the five. Additionally, the method we will use will be 'pmm', which stands for predictive mean matching. That is, the data will be imputed taking the mean as a reference. Once we have generated the imputed data, we have to introduce it in our data. The easiest way to do this is with the `complete()` function, which complete the missing values with the values of the first imputation of the five that we just made.

To check there is no missing data anymore, we use a graph from `library(VIM)` that represent the percentage of missing data.

To check whether the imputed data adequately follows the distributions of the original data, we are going to use the `densityplot()` function, which shows us the marginal distribution of the observed data in blue; and in red, the $m=5$ densities for the predictor that has initially missing data which is `TotalCharges`. That is why, in the following graph, we observe $5$ functions in red, each corresponding to a repetition of the imputed data by `mice`.

```{r counting_NAs, echo=TRUE, results='hide'}
# Counting NA's ----------------------------------------------------------------
missing_values <- colSums(is.na(data)) # 11 NA's in TotalCharges variable
percentage_na <- missing_values/nrow(data)*100 # NA's in %
sort(percentage_na, decreasing = TRUE)

# Get the index of the rows where TotalCharges=NA
index_TotalCharges_na <- which(is.na(data$TotalCharges))
print(index_TotalCharges_na)
```

```{r handling_NAs, fig.width=4, fig.height=3, fig.align='center'}
## MICE Imputation -------------------------------------------------------------
meth <- rep("", ncol(data)) # Set all methods to "" (no imputation)
names(meth)[names(meth) == "TotalCharges"] <- "pmm" # Specify TotalCharges method

mice_model <- mice(data,
  m = 5, maxit = 5, method = "pmm",
  seed = 1234, print = FALSE
)
data <- complete(mice_model, 1) # Complete the data with the first imputation

par(mfrow = c(1, 2)) # Set up plotting area to have 1 row and 2 columns
# Plot 1: Represent the % of missing data
aggr(data,
  col = c("navyblue", "yellow"), numbers = TRUE, sortVars = FALSE,
  labels = names(data), cex.axis = .7, gap = 3,
  ylab = c("Missing data", "Real data")
)

# Plot 2: Check it follows the distribution of the original variable
densityplot(mice_model, scales = list(x = list(relation = "free")))

par(mfrow = c(1, 1)) # Reset par to default
```

Due to it does not fit properly, as we can see on the density plot, I believe setting this observation to $0$ is the best option, among all.

```{r}
# TODO: Establecer estas filas a cero (?) o dejo la imputation.
print(data[489,]) # User with TotalCharges=NA, after imputation
print(data[490,]) # Normal user
```

## 5. Encoding categorical variables.

**Categorical variables**.

-   Binary variables. $11$: `gender`, `SeniorCitizen`, `Partner`, `Dependents`, `OnlineSecurity`, `OnlineBackup`, `DeviceProtection`, `TechSupport`, `StreamingTV`, `StreamingMovies` and `Churn`.

For these variables, I will establish "No" values as $0$ and "Yes" as $1$'s.

-   Multi-sate variables. $4$: `InternetService`, `Contract`, `PaymentMethod`, `PhoneServiceType`.

On the other hand, to manage this section is a little bit more complicated and we need to be aware of the presence or absence of some natural order on it.

Strategy 1: Natural order. `PhoneServiceType` preserve a natural order. As a consequence this parameter, will be encode preserving the order. It is worth to mention that `PhoneServiceType` is already encode. And the idea explained above has been apply, values set as $0$, $1$ and $2$.

Strategy 2: No order. For the second set of categorical parameter (`InternetService`, `Contract` and `PaymentMethod`). I will create factors variables. This is because, for instance, on the `InternetService` parameter, "Fiber Optic" is not inherently greater than "DSL". Same happens with the rest of variables mention.

```{r encoding_categorical_vars, echo=TRUE, results='hide'}
## Binary encoding -------------------------------------------------------------

binary_variables <- c(
  "Partner", "Dependents", "OnlineSecurity", "OnlineBackup",
  "DeviceProtection", "TechSupport", "StreamingTV", "StreamingMovies", "Churn"
)
for (var in binary_variables) {
  data[[var]] <- factor(data[[var]], levels = c("No", "Yes"))
}

data$gender <- factor(data$gender)
levels(data$gender) # Check the levels

## Multi-state variables -------------------------------------------------------
# Rename levels to avoid misunderstands later
# InternetService to a factor and rename levels
data$InternetService <- factor(data$InternetService,
                               levels = c("DSL", "Fiber optic", "No"),
                               labels = c("DSL", "FiberOptic", "No"))
levels(data$InternetService) # Check the levels


# Contract to a factor and rename levels
data$Contract <- factor(data$Contract,
                        levels = c("Month-to-month", "One year", "Two year"),
                        labels = c("MonthToMonth", "OneYear", "TwoYear"))
levels(data$Contract) # Check the levels


# PaymentMethod to a factor and rename levels
data$PaymentMethod <- factor(data$PaymentMethod,
                             levels = c("Electronic check", 
                                        "Mailed check", 
                                        "Bank transfer (automatic)",
                                        "Credit card (automatic)"),
                             labels = c("ElectronicCheck",
                                        "MailedCheck", 
                                        "BankTransfer",
                                        "CreditCard")
                             )
levels(data$PaymentMethod) # Check the levels
```

## 6. Split the dataset

```{r split_dataset, echo=TRUE, results='hide'}
set.seed(1234) # For reproducibility

# Split into training (80%) and testing (20%) set
index <- createDataPartition(data$Churn, p=0.8, list=FALSE)
training <- data[ index,]
testing <- data[-index,]

nrow(training)
nrow(testing)
```

# Exploratory Data Analysis (EDA)

## Numeric variables.

`ggpair` function allow us to create a scatter plot matrix for this three variables. For the visualization of this parameters, I decide to plot histograms.

This matrix provides a visual representation, featuring histogram plots for each variable along the diagonal and showcasing pairwise relationships between variables in the lower triangular section. It also show on the top triangular the correlation coefficients for each pair of variables. The idea is to identify the shape distribution, tendencies, outliers, among other things, thanks to different views in one grid.

```{r scatterPlot_contiuous}
# Select continuous variables
continuous_data <- training[, c("tenure", "MonthlyCharges", "TotalCharges", "Churn")]

# Create matrix of plots
ggpairs(continuous_data,
        aes(fill="pink"),
        lower = list(continuous = "points", combo = "box_no_facet"),
        upper = list(continuous = "cor"),
        diag = list(continuous = "barDiag"),
        title = "Scatter plot matrix"
       )
```

-   **Tenure**

The histogram shows a bimodal distribution, with peaks at the extremes of the range. This implies that most of the customers are either new (low peak) or very loyal (high peak), with fewer clients in the mid-range.

-   **MonthlyCharges**

It can be observe a big peak at the begging of the distribution which represent a big amount of clients that pays around 25\$ per month on this company. On the other hand, there are more less a uniform number of customers that pays from 60\$ to 120\$.

-   **TotalCharges**

It follows a right skewness distribution, which means most of the people are subscribe to services that require to pay less amount of money. It is clear, that clients are willing to pay around $1250 \$$. For trying to achieve a normal distribution I will apply a log transformation on this variable.

If we deeper explore this variable related with the output, we get to the conclusion that clients who have not spent much are more likely to churn (`Churn`=$1$). On the other hand, clients that spend more amount of money, tends to stay more time with this company (`Churn`=$0$).

```{r totalCharges_plot}
ggplot(training, aes(x = TotalCharges, fill = factor(Churn))) +
  geom_density(alpha = 0.5) + # Overlay density plots, alpha: transparency
  scale_fill_manual(values = c("#FFD39B", "lightblue1")) +
  labs(x = "Total Charges", y = "Density", fill = "Churn") +
  theme_minimal() + # Theme
  ggtitle("Density plot of TotalCharges by Churn status")
```

**General insights**. The scatter plot matrix shown that none of the numeric variables follow a normal distribution. Due to the used of some methods, the data will be standardized. In addition, it is worth mentioning the high correlation presented between the variables, which are the ones that are above $0.7$: `tenure`-`TotalCharges` with a coefficient of $0.823$.

```{r numeric_transf}
# Numeric transformation
# TRAINING dataset -------------------------------------------------------------
training_transf <- training
# Log-transformation to solve TotalCharges right skewness
training_transf$TotalCharges <- log(training_transf$TotalCharges)
# Standardizing the variables
training_transf[c("tenure", "MonthlyCharges", "TotalCharges")] <- scale(training_transf[c("tenure", "MonthlyCharges", "TotalCharges")])

# TESTING dataset --------------------------------------------------------------
testing_transf <- testing
# Log-transformation to solve TotalCharges right skewness
testing_transf$TotalCharges <- log(testing_transf$TotalCharges)
# Standardizing the variables
testing_transf[c("tenure", "MonthlyCharges", "TotalCharges")] <- scale(testing_transf[c("tenure", "MonthlyCharges", "TotalCharges")])
```

## Cualitative variables.

**Binary variables**.

In a first general overview thanks to the table, we can see that `gender` as well as `Partner` are data equally represented on the dataset (almost $50\%$). Meanwhile, just around the $16\%$ of the people is a senior citizen, which makes sense and probably will be according to the real representation in a country.

```{r eda_binary_table}
# For binary variables
# Falta meter gender
binary_variables <- c("SeniorCitizen", "Partner", "Dependents", 
                      "OnlineSecurity", "OnlineBackup", "DeviceProtection", 
                      "TechSupport", "StreamingTV", "StreamingMovies")

# Information about data storage on training set -------------------------------
summary(training_transf)
# TODO: Arreglar la tabla
```

The following plots, shows the distribution of churn by each binary variable.

It can clearly, be observed that the lost of clients is very similar independently of the `gender` of the client and if the customer has a partner or not. Something similar happens with the remain variables. It is not a clear pattern.

```{r eda_binary_plot}
# Plots Churn by variable ------------------------------------------------------
plot_churn_distribution <- function(data, variable) {
  plot_data <- data.frame(table(data[[variable]], data$Churn))
  
  ggplot(plot_data, aes(x = Var1, y = Freq, fill = factor(Var2))) +
    geom_bar(stat = "identity") +
    labs(title = paste("Churn distribution by", variable),
         x = variable, y = "Count", fill = "Churn") +
    theme_minimal()
}


plot_list <- lapply(binary_variables, function(variable) {
  plot_churn_distribution(training, variable)
})

library(patchwork)
combined_plots <- wrap_plots(plot_list, ncol = 3)
combined_plots
#grid.arrange(grobs = plot_list, ncol = 3) # Grid 4x3
```

**Category variables**.

Recall there are $4$ variables: `InternetService`, `Contract`, `PaymentMethod`, `PhoneServiceType`. With the following plot we can observed how categories are distribute on a variable. Distribution of `PhoneServiceType` and `InternetService`, lead us into the conclusion that most of the clients choose having phone/internet service above not having. On the other hand, `PaymentMethod` are more less equally distributed hence customer might not have a prefer way to pay. Finally, it looks like clients favorite contract type is to revenue it month by month.

```{r eda_category_distribution}
# InternetService
plot_internetService <- ggplot(training, aes(x = InternetService)) +
  geom_bar(fill = "cornflowerblue") +
  labs(title = "Distribution of Internet Service Types",
       x = "Internet Service",
       y = "Count") +
  theme_minimal()

# Contract
plot_contract <- ggplot(training, aes(x = Contract)) + 
  geom_bar(fill = "coral") +
  labs(title = "Distribution of Contract Types",
       x = "Contract Type", 
       y = "Count") +
  theme_minimal()

# PaymentMethod
plot_paymentMethod <- ggplot(training, aes(x = PaymentMethod)) + 
  geom_bar(fill = "palegreen") +
  labs(title = "Distribution of Payment Methods", 
       x = "Payment Method",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# PhoneServiceType
plot_phoneServiceType <- ggplot(training, aes(x = as.factor(PhoneServiceType))) +
  geom_bar(fill = "orchid") +
  labs(title = "Distribution of Phone Service Types", 
       x = "Phone Service Type", 
       y = "Count") +
  theme_minimal()

# Arrange plots in a grid
grid.arrange(plot_internetService, plot_contract, plot_paymentMethod, plot_phoneServiceType, ncol = 2)
```

Finally, if we study the relationship of these variables with the target we realized that people who design to revenue its contract each $2$ years, are loyal clients (which almost never change to another company). Another insight is that people that pay by electronic check tends to abandon the company more than with other payments.

```{r eda_category_byChurn}
# Melt the training data to long format for faceting
category_data <- melt(training, id.vars = "Churn", measure.vars = c("InternetService", "Contract", "PaymentMethod", "PhoneServiceType"))

# Create the combined plot using the melted data
ggplot(category_data, aes(x = value, fill = Churn)) + 
  geom_bar(position = "fill") +
  scale_fill_manual(values = c("No" = "darkolivegreen3", "Yes" = "brown3")) +
  labs(title = "Relationship with Churn",
       x = "", y = "Proportion") +
  facet_wrap(~variable, scales = "free_x", nrow = 2) +
  theme_minimal() +
  theme(legend.position = "bottom",
        strip.background = element_blank(),
        strip.text.x = element_text(size = 10))
```

## Correlation matrix

```{r correlation_matrix}
# Corr not works for factors:
# 'InternetService', 'Contract', 'PaymentMethod' are not numeric and were ignored
ggcorr(training[,-1], label = T)

# TODO: Arreglar el plot
# TODO: Add some conclusion about variables more influential
```

This matrix give us the strength and direction of relationship between the variables of my dataset. In where, larger values (does not matter if positive or negative) suggest a stronger relationships.

If the coefficient is positive, then this means that if one of the evaluated variables increases (or decreases) the other will also do so. While if the coefficient is negative; While one variable increases, the other decreases.

Next step, consist on getting the determinant and trace of the covariance matrix in order to compare the results of the variables before and after applying the proper transformation.

## Target variable

```{r}
table(data$Churn)

# TODO: Unbalance between the 2 classes (?)
```

We can see that the dataset is imbalanced. There are more people information about Churn=No. This is something, we will must solve.

```{r eval=FALSE}
# In order to check proportion are still the same
table(data$Churn)/length(data$Churn)
table(X_train$Churn)/length(X_train$Churn)
table(X_test$Churn)/length(X_test$Churn)
```

# Statistical tools

This second section aim is to evaluate the performance of different classification models for the binary classification task we are deal with. For each of these techniques, we will also compute the confusion matrix, a tool which will indicate us how many instances were correctly classified and how many were misclassified. The task attempts to estimate whether or not a customer intends to stop using a company's services based on sevaral variables such as gender, monthly charges, and payment method, among others.

```{r}
# Divide into predictors and target both subsets
X_train <- training_transf %>% dplyr::select(-Churn)
#y_train <- training_transf %>% dplyr::select(Churn)
y_train <- training_transf$Churn  # Extract as a vector

X_test <- testing_transf %>% dplyr::select(-Churn)
#y_test <- testing_transf %>% dplyr::select(Churn)
y_test <- testing_transf$Churn  # Extract as a vector
n_test <- dim(testing_transf)[1]
```

## Bayes classifiers

We configure a comon train control parameter.

```{r}
# Set up train control -> 5 repeats of 10-fold cross validation
train_ctrl <- trainControl(method = "repeatedcv",
                           repeats = 5,
                           number = 10)
```

### QDA

```{r}
# Train the QDA model using caret
model_QDA <- train(Churn ~ .,    
                    data = training_transf,
                    method = "qda",
                    trControl = train_ctrl) # Use the defined train control
print(model_QDA)

# Predictions
predictions_QDA <- predict(model_QDA, X_test)
head(predictions_QDA)

# Posterior probabilities
post_prob_QDA <- predict(model_QDA, X_test, type = "prob")
head(post_prob_QDA)

# Performance measures
confMat_QDA <- table(predictions_QDA, testing_transf$Churn)
addmargins(confMat_QDA)

# Error of the model
error_QDA <- (n_test - sum(diag(confMat_QDA))) / n_test
error_QDA

# Plot
ggplot(data = testing_transf, aes(x = seq_along(testing_transf$Churn))) +
  geom_point(aes(y = post_prob_QDA[,"Yes"], color = Churn)) +
  theme_light(base_size = 14) +
  scale_color_manual(values = c("No" = "deepskyblue2", "Yes" = "firebrick2")) +
  xlab("Individual") +
  ylab("Probability of Churn with QDA") +
  geom_hline(yintercept = 0.5, linetype = "dashed")
```

### LDA

```{r}
# Train the LDA model using caret
model_LDA <- train(Churn ~ .,    
                    data = training_transf,
                    method = "lda",
                    trControl = train_ctrl) # Use the defined train control
print(model_LDA)

# Predictions
predictions_LDA <- predict(model_LDA, X_test)
head(predictions_LDA)

# Posterior probabilities
post_prob_LDA <- predict(model_LDA, X_test, type = "prob")
head(post_prob_LDA)

# Performance measures
confMat_LDA <- table(predictions_LDA, testing_transf$Churn)
addmargins(confMat_LDA)

# Error of the model
error_LDA <- (n_test - sum(diag(confMat_LDA))) / n_test
error_LDA

# Plot
ggplot(data = testing_transf, aes(x = seq_along(testing_transf$Churn))) +
  geom_point(aes(y = post_prob_LDA[,"Yes"], color = Churn)) +
  theme_light(base_size = 14) +
  scale_color_manual(values = c("No" = "deepskyblue2", "Yes" = "firebrick2")) +
  xlab("Individual") +
  ylab("Probability of Churn with LDA") +
  geom_hline(yintercept = 0.5, linetype = "dashed")
```

### Naïve Bayes

```{r}
# Train Naive Bayes model
model_NB <- train(x = X_train, 
                  y = y_train, 
                  method = "naive_bayes", 
                  trControl = train_ctrl,
                  tuneLength = data.frame(laplace = 0.5,
                                      usekernel = FALSE,
                                      adjust = FALSE))


# Predict on test data
predictions_NB <- predict(model_NB, newdata = X_test)
head(predictions_NB)

# Posterior probabilities
post_prob_NB <- predict(model_NB, X_test, type = "prob")
head(post_prob_NB)

# Evaluate the model using confusion matrix
confusionMatrix(predictions_NB, y_test)

# Performance measures -> withou using caret
confMat_NB <- table(predictions_NB, testing_transf$Churn)
addmargins(confMat_NB)

# Error of the model
error_NB <- (n_test - sum(diag(confMat_NB))) / n_test
error_NB

# Plot
ggplot(data = testing_transf, aes(x = seq_along(testing_transf$Churn))) +
  geom_point(aes(y = post_prob_NB[,"Yes"], color = Churn)) +
  theme_light(base_size = 14) +
  scale_color_manual(values = c("No" = "deepskyblue2", "Yes" = "firebrick2")) +
  xlab("Individual") +
  ylab("Probability of Churn with Naïve Bayes") +
  geom_hline(yintercept = 0.5, linetype = "dashed")
```

### Shrinkage classification

## Logistic regression

```{r}
model_LR <- train(Churn ~.,
                  data = training_transf,
                  method = "glm",
                  family = "binomial", # For binary logistic regression
                  trControl = train_ctrl)

# Print the model summary
print(model_LR)

# Predict on test data
predictions_LR <- predict(model_LR, X_test)
head(predictions_LR)

# Posterior probabilities
post_prob_LR <- predict(model_LR, X_test, type = "prob")
head(post_prob_LR)

# Evaluate the model using confusion matrix
confusionMatrix(predictions_LR, y_test)

# Performance measures -> without using caret
confMat_LR <- table(predictions_LR, testing_transf$Churn)
addmargins(confMat_LR)

# Error of the model
error_LR <- (n_test - sum(diag(confMat_LR))) / n_test
error_LR

# Plot
ggplot(data = testing_transf, aes(x = seq_along(testing_transf$Churn))) +
  geom_point(aes(y = post_prob_LR[,"Yes"], color = Churn)) +
  theme_light(base_size = 14) +
  scale_color_manual(values = c("No" = "deepskyblue2", "Yes" = "firebrick2")) +
  xlab("Individual") +
  ylab("Probability of Churn with Logistic regression") +
  geom_hline(yintercept = 0.5, linetype = "dashed")
```

## Incorporing economic impact

From all models compute, I choose as the best one the one with lowest error and highest accuracy. This models is the Logistic Regression classifier.

**Recall**. `Churn`: Yes = the customer left the company and No = the customer remained with the company.



Peor error para la company: -\> predecir que se queda (NO) -\> valor real que se vaya (YES)

```         
      Reference
```

Prediction No Yes No 944 168 Yes 90 205

Note: filas (lo que se predice) columnas (valor real)

Peor error en la tabla es: 168

Table of profits:

| Prediction/Actual |  Stay | Leave |
|-------------------|------:|------:|
| Stay              |   0.0 |  -1.0 |
| Leave             | -0.01 |   0.0 |

For instance, a naive manager would incur a profit per applicant of $0.12\times0.93 - 1.0\times0.07 - 0.01\times0.0 + 0.0\times0.0 = 0.0416$

This is the profit we should improve

Profit table as a vector:

```{r}
profit.unit <- c(0.12, -0.01, -1.0, 0.0)

## Selecting the optimal threshold to give the loan
profit.i = matrix(NA, nrow = 50, ncol = 10)
# 100 replicates for training/testing sets for each of the 10 values of threshold

p0=0.8
p1=1-p0

j <- 0

# This is for doing hyper-parameter
for (threshold in seq(0.05,0.5,0.05)){
  #for (p1 in c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.75, 0.8, 0.9)){
  
  j <- j + 1
  cat(j)
  for(i in 1:50){
    
    # partition data intro training (40%) and testing sets (60%)
    d <- createDataPartition(training_transf$Churn, p = 0.4, list = FALSE)
    # select training sample
    
    train<-training[d,]
    test <-training[-d,]  
    
    #p1=1-p0
    # Fit logistic regression model
    full.model <- glm(Churn ~ ., data = train, family = "binomial")
    
    # Obtain predicted probabilities on test set
    probabilities <- predict(full.model, newdata = test, type = "response")

    # Convert probabilities to predicted classes based on threshold
    Churn_pred <- ifelse(probabilities > threshold, "Yes", "No")
    
    # Create confusion matrix
    CM <- table(Churn_pred, test$Churn)

    # Calculate profit per applicant
    profit.applicant <- sum(profit.unit*CM)/sum(CM)
    profit.i[i,j] <- profit.applicant
    
  }
}


boxplot(profit.i, main = "Hyper-parameter selection",
        ylab = "unit profit",
        xlab = "threshold", names = seq(0.05,0.5,0.05),col="royalblue2")


apply(profit.i, 2, median) 
```

```{r eval=FALSE}
lr.model <- glm(Churn ~ ., data = train, family = "binomial")
probability = predict(lr.model, testing_transf$Churn)$posterior
threshold = 0.019096421
Cred.pred = rep("Good", nrow(testing))
Cred.pred[which(probability[,2] > threshold)] = "Bad"
CM = confusionMatrix(factor(Cred.pred), testing$Creditability)$table
profit.applicant <- sum(profit.unit*CM)/sum(CM)
profit.applicant
```

# Conclusion

```{r}
############ Summary ERRORS ############
## QDA -----------------------------------------------
# Sin balanceo, sin log-transformation: 23.52523%
# Sin balanceo, con log-transformation: 22.95665
## LDA -----------------------------------------------
# Sin balanceo, sin log-transformation: 18.8344%
# Sin balanceo, con log-transformation: 18.69225%
## NB ------------------------------------------------
# Sin balanceo, sin log-transformation: 22.10377%
# Sin balanceo, sin log-transformation: 21.39% (with caret)
# Sin balanceo, con log-transformation: 21.03767%

## Shrinkage -----------------------------------------

## LR ------------------------------------------------
# Sin balanceo, sin log-transformation: 19.62% (with caret)
# Sin balanceo, con log-transformation: 18.33689%
```

# References

```{r eval=FALSE, echo=FALSE}
# Returns the names of all packages loaded in the current R session
# knitr::write_bib(.packages(), "references.bib")
```

::: {#refs}
:::
