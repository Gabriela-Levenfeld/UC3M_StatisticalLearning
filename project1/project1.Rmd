---
title: 'Project 1: Statistical Tools'
author: "Gabriela Levenfeld Sabau"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: '6'
    df_print: paged
  geometry: left=3cm,right=3cm,top=2cm,bottom=2cm
  mathjax: local
  self_contained: false
  word_document:
    toc: true
    toc_depth: '6'
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 6
    keep_tex: true
subtitle: MS in Statistics for Data Science
bibliography: references.bib
nocite: '@*'
link-citations: true
linkcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

\pagebreak

# Introduction

## Dataset description

Data can be found in Kaggle: <https://www.kaggle.com/datasets/blastchar/telco-customer-churn>.

It contains information from $7043$ clients distributed into $21$ different variables.

This dataset is made in order to predict *customer churn*. In the business sector, in order to make a profit, the number of customers gained and lost is really important. It not only allow us to compute the benefit that a company can have, it is also a good metric to evaluate and get insight about the strategy we are employing. This, let us to make decisions to make the next steps.

## Variables description

The information contained in this dataset can be group into different areas.

\underline{Personal information about the customer}.

- `customerID`: Unique identifier for the client.

- `gender`: Female or Male.

- `SeniorCitizen`: Binary variable that indicates if >65 (yes) or not (no).

- `Partner`: Whether the customer has a partner or not (Yes, No).

- `Dependents`: Variables which storage if the client lives with more people (children, parents, grandparents,...).

\underline{Services subscribed}.

- `tenure`: Indicates the total amount of months that the customer has been with the company by the end of the 3Q (third quarter).

- `PhoneService`: Yes if client is subscribed to home phone service with the company and No if not.

- `MultipleLines`: Yes if the client has more than 1 telephone lines with the company and No if just one.

- `InternetService`:  Indicates if the customer subscribes to Internet service with the company: No, DSL, Fiber Optic, Cable. 4 options are available.

- `OnlineSecurity`: Yes if the client has online security service (extra service) provided by the company and No if not.

- `OnlineBackup`:  Indicates if the customer subscribes to an additional online backup service provided by the company: Yes, No.

- `DeviceProtection`: Indicates if the customer subscribes to an additional device protection plan for their Internet equipment provided by the company: Yes, No.

- `TechSupport`: Indicates if the customer subscribes to an additional technical support plan from the company with reduced wait times: Yes, No.

- `StreamingTV`: Indicates if the customer uses their Internet service to stream television programing from a third party provider: Yes, No. The company does not charge an additional fee for this service.

- `StreamingMovies`: Indicates if the customer uses their Internet service to stream movies from a third party provider: Yes, No. The company does not charge an additional fee for this service

\underline{Account information}

- `Contract`: Indicates the customer’s current contract type: Month-to-Month, One Year, Two Year.

- `PaperlessBilling`: Indicates if the customer has chosen paperless billing: Yes, No.

- `PaymentMethod`: Indicates how the customer pays their bill: Bank Withdrawal, Credit Card, Mailed Check.

- `MonthlyCharges`:  Indicates the customer’s current total monthly charge for all their services from the company.

- `TotalCharges`: Indicates the customer’s total charges, calculated to the end of the 3Q (third quarter).

\underline{Target variable}

- `Churn`: Yes = the customer left the company this quarter. No = the customer remained with the company.


## Goal

Prediction over the `Churn` variable. Binary classification problem, where we want to predict is a client is going to continue with the services provided by the company. Or if he is going to leave.

\pagebreak
# Data preprocessing

In this first section, we must prepare the dataset in order to use it for the computational model. This means handling missing data, deleting unnecessary information, encoding categorical variables and splitting the data, among other.


## 1. Load material.

**Load libraries**. Several libraries are need for the project in order to work properly.

```{r load_libraries, message=FALSE, warning=FALSE}
library(skimr)
library(tidyverse) # For glimpse
library(dplyr) # mutate function
library(mice) # Imputation
library(VIM) # Imputation graph
library(fastDummies) # For encoding multi-state variables
library(caret) # For split the dataset
library(ggplot2) # Plots
library(GGally) # For plots of the continuous variables
library(pander) # For making tables
library(gridExtra) # For grid.arrange
library(reshape2) # For melt function
library(corrplot) # For correlation matrix
library(MASS) # For qda and lda
```

**Load dataset**.

```{r load_data}
# Load the dataset for this project
data <- read.csv("Telco-Customer-Churn.csv", header = TRUE, sep = ",")
```

**First look at the dataset**.

```{r small_EDA}
# Small Exploratory Data Analysis
#skim(data)
# Presents results for every column; the statistics it provides depend on the class of the variable

glimpse(data)

# For visualize the first 2 rows
#head(data, 2)
```

## 2. Delete unnecessary information.

Thanks to the above function, we realized we can remove the ID column (`customerID`) because it will not be useful for making predictions. On the other hand, `PaperlessBilling` is also removed, due to nowadays we live in a digital era thus most people choose electronic payments and it will not really provide any additional information to the problem we are dealing with.

```{r rmv_columns}
# Remove ID column 
data <- data %>% dplyr::select(-c(customerID, PaperlessBilling))
```

## 3. Data cleaning.

By analyzing the dataset we can realized that there exists some variables that are quite intertwine.

\underline{Combine `PhoneService` and `MultipleLines`}. The first variable indicates if the client has sign up for home phone service or not. Only when the client has hired for this service, he can choose between having $1$ phone line (`MultipleLines`=No) or have more than $1$ (`MultipleLines`=Yes). This relationship lead us into three possible scenarios:

1. `PhoneService`=No and `MultipleLines`="No phone service". Customers who do not have phone service.

2. `PhoneService`=Yes and `MultipleLines`=No. Customers who have phone service and choose to have a single line.

3. `PhoneService`=Yes and `MultipleLines`=Yes. Customers who have phone service and choose to have multiple lines.

Since `MultipleLines` can be consider to have all the information needed, I will combine this two variables on a new parameter named `PhoneServiceType` and treat it as a multi-state category with three options:

- $0$: if there is no phone service.

- $1$: if there is phone service with a single line.

- $2$: if there is phone service with multiple lines.

\underline{`InternetService` and its associate variables}. Something similar happend on this situation. Clients who have no sign up for Internet service, they are no be able to sign up for extra-services associated with it such as `OnlineSecurity`, `StreamingTV`, among others. The dataset storage this information of extra-services with "Yes", "No" or "No internet service". It is clearly that we can reduce this multi-state variables issue into a binary class. So "No phone service" will be understand simply as the customer does not have this service on (setting the parameter value into "No").

**Note**: For both situation, we check there was no mistake on the data. So it has been computationally verified that there is concordance between the relationships of these variables. Thus avoiding the existence of possible nonsense situations.


```{r data_cleaning, echo=TRUE, results='hide'}
## Unique values of each variable ----------------------------------------------
unique(data$SeniorCitizen) # It is already transform in 1's and 0's

cat_vars <- sapply(data, is.character) # Select qualitative variables
lapply(data[, cat_vars], unique) # Print unique values


## PhoneService and MultipleLines ----------------------------------------------
# Subset with clients where PhoneService is "No"
subset_no_Phone <- data[data$PhoneService == "No", ]
# Check MultipleLines is set to "No phone service"
if (all(subset_no_Phone$MultipleLines == "No phone service")) {
  cat("In the subset where PhoneService is 'No', 
      MultipleLines is set to 'No phone service' only.\n")
} else {
  cat("In the subset where PhoneService is 'No', 
      MultipleLines is not exclusively set to 'No phone service'.\n")
}

# Combine PhoneService and MultipleLines on a new variable (PhoneServiceType)
data <- data %>%
  mutate(PhoneServiceType = case_when(
    MultipleLines == "No phone service" ~ 0,
    MultipleLines == "No" ~ 1,
    TRUE ~ 2
  ))

# Remove original variables
data <- dplyr::select(data, -PhoneService, -MultipleLines)


## Consequences Internet service -----------------------------------------------
# Subset with clients where InternetService is "No"
subset_no_Internet <- data[data$InternetService == "No", ]

vars_to_check <- c("OnlineSecurity", "OnlineBackup", "DeviceProtection",
                   "TechSupport", "StreamingTV", "StreamingMovies")

# Check its associate variables are set to "No internet service"
for (variable in vars_to_check) {
  unique_values <- unique(subset_no_Internet[[variable]])
  cat("Unique values for", variable, ":", unique_values)
  cat("\n")
}

# Reduce the associate variables to a binary class ("No internet service" -> "No")
for (variable in vars_to_check) {
  data[[variable]] <- ifelse(data[[variable]] == "No internet service", "No", data[[variable]])
}
```

## 4. Handling missing data.

On this dataset there are some missing values contained in the variable `TotalCharges` which we need to handle it first in order to be able to use the statistical tools after.

Take in mind, these values represent only $0.1561834\%$ of customers in the dataset, the following approach could be followed:

- **Delete this rows**; due to the low presence of missing values the data will not be affected.

- **Set to $0$**; these observations correspond to new clients, therefore, not it has not passed enough time to compute this value.

- **Imputation**; selected option thereby some techniques seen during lecture can be apply.

For imputing the missing data the R library call `mice` is used. Instead of making a random prediction, `mice` by default makes $5$. However, in this exercise we will only choose the first of the five. Additionally, the method we will use will be 'pmm', which stands for predictive mean matching. That is, the data will be imputed taking the mean as a reference. Once we have generated the imputed data, we have to introduce it in our data. The easiest way to do this is with the `complete()` function, which complete the missing values with the values of the first imputation of the five that we just made.

To check there is no missing data anymore, we use a graph from `library(VIM)` that represent the percentage of missing data.

To check whether the imputed data adequately follows the distributions of the original data, we are going to use the `densityplot()` function, which shows us the marginal distribution of the observed data in blue; and in red, the $m=5$ densities for the predictor that has initially missing data which is `TotalCharges`. That is why, in the following graph, we observe $5$ functions in red, each corresponding to a repetition of the imputed data by `mice`.

```{r counting_NAs, echo=TRUE, results='hide'}
# Counting NA's ----------------------------------------------------------------
missing_values <- colSums(is.na(data)) # 11 NA's in TotalCharges variable
percentage_na <- missing_values/nrow(data)*100 # NA's in %
sort(percentage_na, decreasing = TRUE)

# Get the index of the rows where TotalCharges=NA
index_TotalCharges_na <- which(is.na(data$TotalCharges))
print(index_TotalCharges_na)
```

```{r handling_NAs, fig.width=4, fig.height=3, fig.align='center'}
## MICE Imputation -------------------------------------------------------------
meth <- rep("", ncol(data)) # Set all methods to "" (no imputation)
names(meth)[names(meth) == "TotalCharges"] <- "pmm" # Specify TotalCharges method

mice_model <- mice(data,
  m = 5, maxit = 5, method = "pmm",
  seed = 1234, print = FALSE
)
data <- complete(mice_model, 1) # Complete the data with the first imputation

par(nfrow=c(1,2))
# Represent the % of missing data
aggr(data,
  col = c("navyblue", "yellow"), numbers = TRUE, sortVars = FALSE,
  labels = names(data), cex.axis = .7, gap = 3,
  ylab = c("Missing data", "Real data")
)

# Check it follows the distribution of the original variable
densityplot(mice_model, scales = list(x = list(relation = "free")))
```

Due to it does not fit properly, as we can see on the density plot, I believe setting this observation to $0$ is the best option, among all.

```{r}
# TODO: Establecer estas filas a cero (?) o dejo la imputation.
print(data[489,]) # User with TotalCharges=NA, after imputation
print(data[490,]) # Normal user
```


## 5. Encoding categorical variables.

**Categorical variables**.

- Binary variables. $11$: `gender`, `SeniorCitizen`, `Partner`, `Dependents`, `OnlineSecurity`, `OnlineBackup`, `DeviceProtection`, `TechSupport`, `StreamingTV`, `StreamingMovies` and `Churn`.

For these variables, I will establish "No" values as $0$ and "Yes" as $1$'s.

- Multi-sate variables. $4$: `InternetService`, `Contract`,  `PaymentMethod`, `PhoneServiceType`.

On the other hand, to manage this section is a little bit more complicated and we need to be aware of the presence or absence of some natural order on it.

Strategy 1: Natural order.
`PhoneServiceType` preserve a natural order. As a consequence this parameter, will be encode preserving the order. It is worth to mention that `PhoneServiceType` is already encode. And the idea explained above has been apply, values set as $0$, $1$ and $2$.

Strategy 2: No order.
For the second set of categorical parameter (`InternetService`, `Contract` and `PaymentMethod`). I will create factors variables. This is because, for instance, on the `InternetService` parameter, "Fiber Optic" is not inherently greater than "DSL". Same happens with the rest of variables mention.

```{r encoding_categorical_vars, echo=TRUE, results='hide'}
## Binary encoding -------------------------------------------------------------
data$gender <- as.integer(data$gender == "Female") # Assuming Female:1, Male:0

data$Churn <- factor(data$Churn)
levels(data$Churn) # Check the levels

binary_variables <- c(
  "Partner", "Dependents", "OnlineSecurity", "OnlineBackup",
  "DeviceProtection", "TechSupport", "StreamingTV", "StreamingMovies"
)
# Assuming Yes:1, No:0
data[binary_variables] <- lapply(data[binary_variables],
                                 function(x) as.integer(x == "Yes"))


## Multi-state variables -------------------------------------------------------
# Rename levels to avoid misunderstands later
# InternetService to a factor and rename levels
data$InternetService <- factor(data$InternetService,
                               levels = c("DSL", "Fiber optic", "No"),
                               labels = c("DSL", "FiberOptic", "No"))
levels(data$InternetService) # Check the levels


# Contract to a factor and rename levels
data$Contract <- factor(data$Contract,
                        levels = c("Month-to-month", "One year", "Two year"),
                        labels = c("MonthToMonth", "OneYear", "TwoYear"))
levels(data$Contract) # Check the levels


# PaymentMethod to a factor and rename levels
data$PaymentMethod <- factor(data$PaymentMethod,
                             levels = c("Electronic check", 
                                        "Mailed check", 
                                        "Bank transfer (automatic)",
                                        "Credit card (automatic)"),
                             labels = c("ElectronicCheck",
                                        "MailedCheck", 
                                        "BankTransfer",
                                        "CreditCard")
                             )
levels(data$PaymentMethod) # Check the levels
```

## 6. Split the dataset

```{r split_dataset, echo=TRUE, results='hide'}
set.seed(1234) # For reproducibility

# Split into training (80%) and testing (20%) set
index <- createDataPartition(data$Churn, p=0.8, list=FALSE)
training <- data[ index,]
testing <- data[-index,]

nrow(training)
nrow(testing)
```


# Exploratory Data Analysis (EDA)

## Numeric variables.

`ggpair` function allow us to create a scatter plot matrix for this three variables. For the visualization of this parameters, I decide to plot histograms.

This matrix provides a visual representation, featuring histogram plots for each variable along the diagonal and showcasing pairwise relationships between variables in the lower triangular section. It also show on the top triangular the correlation coefficients for each pair of variables. 
The idea is to identify the shape distribution, tendencies, outliers, among other things, thanks to different views in one grid.


```{r scatterPlot_contiuous}
# Select continuous variables
continuous_data <- training[, c("tenure", "MonthlyCharges", "TotalCharges", "Churn")]

# Create matrix of plots
ggpairs(continuous_data,
        aes(fill="pink"),
        lower = list(continuous = "points", combo = "box_no_facet"),
        upper = list(continuous = "cor"),
        diag = list(continuous = "barDiag"),
        title = "Scatter plot matrix"
       )
```

- **Tenure**

The histogram shows a bimodal distribution, with peaks at the extremes of the range. This implies that most of the customers are either new (low peak) or very loyal (high peak), with fewer clients in the mid-range.

- **MonthlyCharges**

It can be observe a big peak at the begging of the distribution which represent a big amount of clients that pays around 25\$ per month on this company. On the other hand, there are more less a uniform number of customers that pays from 60\$ to 120\$. 

- **TotalCharges**

It follows a right skewness distribution, which means most of the people are subscribe to services that require to pay less amount of money. It is clear, that clients are willing to pay around $1250 \$$.

If we deeper explore this variable related with the output, we get to the conclusion that clients who have not spent much are more likely to churn (`Churn`=$1$). On the other hand, clients that spend more amount of money, tends to stay more time with this company (`Churn`=$0$).

```{r totalCharges_plot}
ggplot(training, aes(x = TotalCharges, fill = factor(Churn))) +
  geom_density(alpha = 0.5) + # Overlay density plots, alpha: transparency
  scale_fill_manual(values = c("#FFD39B", "lightblue1")) +
  labs(x = "Total Charges", y = "Density", fill = "Churn") +
  theme_minimal() + # Theme
  ggtitle("Density plot of TotalCharges by Churn status")
```


**General insights**. The scatter plot matrix shown that none of the numeric variables follow a normal distribution. Due to the used of some methods, the data will be standardized. In addition, it is worth mentioning the high correlation presented between the variables, which are the ones that are above $0.7$: `tenure`-`TotalCharges` with a coefficient of $0.823$.

```{r numeric_transf}
# Numeric transformation
# TRAINING dataset -------------------------------------------------------------
training_transf <- training
# Standardizing the variables
training_transf[c("tenure", "MonthlyCharges", "TotalCharges")] <- scale(training_transf[c("tenure", "MonthlyCharges", "TotalCharges")])

# TESTING dataset --------------------------------------------------------------
testing_transf <- testing
# Standardizing the variables
testing_transf[c("tenure", "MonthlyCharges", "TotalCharges")] <- scale(testing_transf[c("tenure", "MonthlyCharges", "TotalCharges")])
```


## Cualitative variables.

**Binary variables**.

In a first general overview thanks to the table, we can see that `gender` as well as `Partner` are data equally represented on the dataset (almost $50\%$). Meanwhile, just around the $16\%$ of the people is a senior citizen, which makes sense and probably will be according to the real representation in a country.

```{r eda_binary_table}
# For binary variables
binary_variables <- c("gender", "SeniorCitizen", "Partner", "Dependents", 
                      "OnlineSecurity", "OnlineBackup", "DeviceProtection", 
                      "TechSupport", "StreamingTV", "StreamingMovies")

# Information about data storage on training set -------------------------------
mean_binary_values <- sapply(training[binary_variables], mean)
mean_binary_table <- data.frame(Mean = mean_binary_values)
pander(mean_binary_table)
```

The following plots, shows the distribution of churn by each binary variable.

It can clearly, be observed that the lost of clients is very similar independently of the `gender` of the client and if the customer has a partner or not.
Something similar happens with the remain variables. It is not a clear pattern.

```{r eda_binary_plot}
# Plots Churn by variable ------------------------------------------------------
plot_churn_distribution <- function(data, variable) {
  plot_data <- data.frame(table(data[[variable]], data$Churn))
  
  ggplot(plot_data, aes(x = Var1, y = Freq, fill = factor(Var2))) +
    geom_bar(stat = "identity") +
    labs(title = paste("Churn distribution by", variable),
         x = variable, y = "Count", fill = "Churn") +
    theme_minimal()
}


plot_list <- lapply(binary_variables, function(variable) {
  plot_churn_distribution(training, variable)
})

library(patchwork)
combined_plots <- wrap_plots(plot_list, ncol = 3)
combined_plots
#grid.arrange(grobs = plot_list, ncol = 3) # Grid 4x3
```

**Category variables**.

Recall there are $4$ variables: `InternetService`, `Contract`,  `PaymentMethod`, `PhoneServiceType`. With the following plot we can observed how categories are distribute on a variable. Distribution of `PhoneServiceType` and `InternetService`, lead us into the conclusion that most of the clients choose having phone/internet service above not having. On the other hand, `PaymentMethod` are more less equally distributed hence customer might not have a prefer way to pay. Finally, it looks like clients favorite contract type is to revenue it month by month.

```{r eda_category_distribution}
# InternetService
plot_internetService <- ggplot(training, aes(x = InternetService)) +
  geom_bar(fill = "cornflowerblue") +
  labs(title = "Distribution of Internet Service Types",
       x = "Internet Service",
       y = "Count") +
  theme_minimal()

# Contract
plot_contract <- ggplot(training, aes(x = Contract)) + 
  geom_bar(fill = "coral") +
  labs(title = "Distribution of Contract Types",
       x = "Contract Type", 
       y = "Count") +
  theme_minimal()

# PaymentMethod
plot_paymentMethod <- ggplot(training, aes(x = PaymentMethod)) + 
  geom_bar(fill = "palegreen") +
  labs(title = "Distribution of Payment Methods", 
       x = "Payment Method",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# PhoneServiceType
plot_phoneServiceType <- ggplot(training, aes(x = as.factor(PhoneServiceType))) +
  geom_bar(fill = "orchid") +
  labs(title = "Distribution of Phone Service Types", 
       x = "Phone Service Type", 
       y = "Count") +
  theme_minimal()

# Arrange plots in a grid
grid.arrange(plot_internetService, plot_contract, plot_paymentMethod, plot_phoneServiceType, ncol = 2)
```

Finally, if we study the relationship of these variables with the target we realized that people who design to revenue its contract each $2$ years, are loyal clients (which almost never change to another company). Another insight is that people that pay by electronic check tends to abandon the company more than with other payments.

```{r eda_category_byChurn}
# Melt the training data to long format for faceting
category_data <- melt(training, id.vars = "Churn", measure.vars = c("InternetService", "Contract", "PaymentMethod", "PhoneServiceType"))

# Create the combined plot using the melted data
ggplot(category_data, aes(x = value, fill = Churn)) + 
  geom_bar(position = "fill") +
  scale_fill_manual(values = c("No" = "darkolivegreen3", "Yes" = "brown3")) +
  labs(title = "Relationship with Churn",
       x = "", y = "Proportion") +
  facet_wrap(~variable, scales = "free_x", nrow = 2) +
  theme_minimal() +
  theme(legend.position = "bottom",
        strip.background = element_blank(),
        strip.text.x = element_text(size = 10))
```


## Correlation matrix

```{r correlation_matrix}
# Corr not works for factors:
# 'InternetService', 'Contract', 'PaymentMethod' are not numeric and were ignored
ggcorr(training[,-1], label = T)

# TODO: Arreglar el plot
# TODO: Add some conclusion about variables more influential
```


This matrix give us the strength and direction of relationship between the variables of my dataset. In where, larger values (does not matter if positive or negative) suggest a stronger relationships.

If the coefficient is positive, then this means that if one of the evaluated variables increases (or decreases) the other will also do so. While if the coefficient is negative; While one variable increases, the other decreases.

Next step, consist on getting the determinant and trace of the covariance matrix in order to compare the results of the variables before and after applying the proper transformation.


## Target variable

```{r}
table(data$Churn)

# TODO: Unbalance between the 2 classes (?)
```

We can see that the dataset is imbalanced. There are more people information about Churn=No. This is something, we will must solve.

```{r eval=FALSE}
# In order to check proportion are still the same
table(data$Churn)/length(data$Churn)
table(X_train$Churn)/length(X_train$Churn)
table(X_test$Churn)/length(X_test$Churn)
```


# Statistical tools

This second section aim is to evaluate the performance of different classification models for the binary classification task we are deal with. For each of these techniques, we will also compute the confusion matrix, a tool which will indicate us how many instances were correctly classified and how many were misclassified.
The task attempts to estimate whether or not a customer intends to stop using a company's services based on sevaral variables such as gender, monthly charges, and payment method, among others.

```{r}
# Divide into predictors and target both subsets
X_train <- training_transf
y_train <- training_transf %>% dplyr::select(Churn)

X_test <- testing_transf
y_test <- testing_transf %>% dplyr::select(Churn)
```

## Bayes classifiers

### QDA

```{r}
model_QDA <- qda(Churn~., data=training_transf)
model_QDA
```

```{r eval=FALSE}
# TODO: Not working
# Exploratory graph for QDA
library(klaR)
partimat(Churn ~ ., data=training_transf, method="qda")
```

```{r}
# Predictions
post_prob_qda = predict(model_QDA, training_transf)$posterior
head(post_prob_qda)

# QDA into labels
predictions_QDA = predict(model_QDA, training_transf)$class
head(predictions_QDA)
```

**Scatterplot with predictions**: good classifications in red and bad classifications in black

QDA:

```{r}
colors_qda_good_bad <- c("black","red")[1*(training_transf[,5]==predictions_QDA)+1]
pairs(training_transf[,1:4], 
      main="Bad (in black) classifications with QDA",
      pch=19, 
      col=colors_qda_good_bad, 
      lower.panel=NULL)
```


**Performance measures**

Summarize accuracy (confusion matrix)

```{r}
confMat_QDA = table(predictions_QDA, training_transf$Churn)
confMat_QDA
```

```{r}
n <- dim(training_transf)[1]
error_QDA <- (n - sum(diag(confMat_QDA)))/n
error_QDA
# 24.21%, sin previo balanceo de clases
```

### LDA

```{r}
model_LDA <- lda(Churn~., data=training_transf)
model_LDA

# TODO: (Not working) Exploratory Graph for LDA
#partimat(Churn~., data=training_transf, methis='lda')

n_test <- dim(testing_transf)[1]

# Predictions
predictions_LDA <- predict(model_LDA, X_test)
# Posterior probabilities
post_prob_LDA <- predictions_LDA$posterior
head(post_prob_LDA)
# LDA into labels 
predictions_LDA_label <- predictions_LDA$class 
head(predictions_LDA_label)

# TODO: Weird output
# Scatterplot with predictions: good->red and bad->black
colors_lda_goodbad<-c("black","red")[1*(training_transf[,5]==predictions_LDA)+1]
pairs(testing_transf[,1:4],
      main="Bad (in black) classifications for LDA",
      pch=19,
      col=colors_lda_goodbad,
      lower.panel=NULL)

# Plot
ggplot(testing_transf,
       aes(x=1:n_test, y=predictions_LDA$posterior[,2], color=Churn)) +
  theme_light(base_size=8) +
  geom_point(size=1) + 
  scale_color_manual(values=c("deepskyblue2","firebrick2")) +
  xlab("Individual") +
  ylab("Probability of default with LDA") +
  geom_hline(yintercept=0.5)

# Performance measures
confMat_LDA <- table(predictions_LDA$class,testing_transf$Churn)
addmargins(confMat_LDA)
error_LDA <- (n_test-sum(diag(confMat_LDA)))/n_test
error_LDA #18.8344%
```


### Naïve Bayes
### Shrinkage classification
## Logistic regression
# Conclusion
# References

```{r eval=FALSE, echo=FALSE}
# Returns the names of all packages loaded in the current R session
# knitr::write_bib(.packages(), "references.bib")
```

<div id="refs"></div>
